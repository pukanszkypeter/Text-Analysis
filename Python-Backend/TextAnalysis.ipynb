{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB Connection\n",
    "import sqlite3\n",
    "\n",
    "# Casual\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# For Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# For Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# NLTK\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.classify import SklearnClassifier\n",
    "import re\n",
    "\n",
    "# Wordcloud\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "\n",
    "# Train - Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Testing\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Dump Models\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### SZÖVEGELEMZÉS (KATEGÓRIA PREDIKTÁLÁS, ÉRZELEM OSZTÁLYOZÁS) ####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adatbázis\n",
    "\n",
    "connection = sqlite3.connect(\"podcasts.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### 1. KATEGÓRIA PREDIKCIÓ - TELJES ####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adat betöltés\n",
    "\n",
    "full_cat_pred = pd.read_sql(\"select reviews.content, categories.category from reviews, categories where reviews.podcast_id = categories.podcast_id\", connection)\n",
    "full_cat_pred_content = full_cat_pred['content'].values.tolist()\n",
    "full_cat_pred_category = full_cat_pred['category'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer()),\n",
       "                ('multinomialnb', MultinomialNB())])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tanulás\n",
    "\n",
    "fullcatpred = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "fullcatpred.fit(full_cat_pred_content, full_cat_pred_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['business']\n"
     ]
    }
   ],
   "source": [
    "# Prediktálás\n",
    "\n",
    "def predict_category_full(s):\n",
    "    pred = fullcatpred.predict([s])\n",
    "    return pred\n",
    "\n",
    "print(predict_category_full('bank system, valuta, credit card'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mentés\n",
    "\n",
    "pickle.dump(fullcatpred, open('fullcatpred.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### 2. KATEGÓRIA PREDIKCIÓ - RÉSZLEGES ####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adat betöltés\n",
    "\n",
    "par_cat_pred = pd.read_sql(\"select reviews.content, categories.category from reviews, categories where reviews.podcast_id = categories.podcast_id\", connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Szelektálás\n",
    "\n",
    "categories = ['technology', 'arts-food','hinduism', 'spirituality']\n",
    "\n",
    "def decision_maker(subject, categories):\n",
    "    x = False\n",
    "    for cat in categories:\n",
    "        if subject == cat:\n",
    "            x = True  \n",
    "    return x\n",
    "\n",
    "par_cat_pred_content = []\n",
    "par_cat_pred_category = []\n",
    "\n",
    "for ind in par_cat_pred.index:\n",
    "    if (decision_maker(par_cat_pred['category'][ind], categories)):\n",
    "        par_cat_pred_content.append(par_cat_pred['content'][ind])\n",
    "        par_cat_pred_category.append(par_cat_pred['category'][ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer()),\n",
       "                ('multinomialnb', MultinomialNB())])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tanulás\n",
    "\n",
    "parcatpred = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "parcatpred.fit(par_cat_pred_content, par_cat_pred_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arts-food']\n"
     ]
    }
   ],
   "source": [
    "# Prediktálás\n",
    "\n",
    "def predict_category_par(s):\n",
    "    pred = parcatpred.predict([s])\n",
    "    return pred\n",
    "\n",
    "print(predict_category_par('hamburger, tasty, cheese, milk'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mentés\n",
    "\n",
    "# Web alkalmazás logika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### 3. ÉRZELEM OSZTÁLYOZÁS ####################\n",
    "# https://stackabuse.com/python-for-nlp-sentiment-analysis-with-scikit-learn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    996894\n",
       "0    151320\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adat betöltés\n",
    "\n",
    "sentiment_data = pd.read_sql(\"\"\"\n",
    "    select\n",
    "        content,\n",
    "        case when rating < 5 then 0\n",
    "            when rating > 4 then 1\n",
    "        end as sentiment\n",
    "    from reviews\n",
    "\"\"\", connection)\n",
    "\n",
    "sentiment_data.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adat csökkentés\n",
    "\n",
    "sentiment_data_positive = sentiment_data[sentiment_data['sentiment'] == 1].head(150000)\n",
    "sentiment_data_negative = sentiment_data[sentiment_data['sentiment'] == 0].head(150000)\n",
    "\n",
    "frames = [sentiment_data_positive, sentiment_data_negative]\n",
    "\n",
    "sentiment = pd.concat(frames, ignore_index=True)\n",
    "features = sentiment.content\n",
    "labels = sentiment.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tisztítás\n",
    "\n",
    "processed_features = []\n",
    "\n",
    "for sentence in range(0, len(features)):\n",
    "    # Remove all the special characters\n",
    "    processed_feature = re.sub(r'\\W', ' ', str(features[sentence]))\n",
    "\n",
    "    # remove all single characters\n",
    "    processed_feature= re.sub(r'\\s+[a-zA-Z]\\s+', ' ', processed_feature)\n",
    "\n",
    "    # Remove single characters from the start\n",
    "    processed_feature = re.sub(r'\\^[a-zA-Z]\\s+', ' ', processed_feature) \n",
    "\n",
    "    # Substituting multiple spaces with single space\n",
    "    processed_feature = re.sub(r'\\s+', ' ', processed_feature, flags=re.I)\n",
    "\n",
    "    # Removing prefixed 'b'\n",
    "    processed_feature = re.sub(r'^b\\s+', '', processed_feature)\n",
    "\n",
    "    # Converting to Lowercase\n",
    "    processed_feature = processed_feature.lower()\n",
    "\n",
    "    processed_features.append(processed_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF - IDF\n",
    "\n",
    "vectorizer = TfidfVectorizer (max_features=200, min_df=7, max_df=0.8, stop_words=stopwords.words('english'))\n",
    "processed_features = vectorizer.fit_transform(processed_features).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF - IDF Mentés\n",
    "\n",
    "pickle.dump(vectorizer, open('tfidf.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train - Test Split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(processed_features, labels, test_size=0.05, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=200, random_state=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tanulás\n",
    "\n",
    "text_classifier = RandomForestClassifier(n_estimators=200, random_state=0)\n",
    "text_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Mentés\n",
    "\n",
    "pickle.dump(text_classifier, open('textclassifier.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5822 1625]\n",
      " [1730 5823]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.78      0.78      7447\n",
      "           1       0.78      0.77      0.78      7553\n",
      "\n",
      "    accuracy                           0.78     15000\n",
      "   macro avg       0.78      0.78      0.78     15000\n",
      "weighted avg       0.78      0.78      0.78     15000\n",
      "\n",
      "0.7763333333333333\n"
     ]
    }
   ],
   "source": [
    "# Tesztelés\n",
    "\n",
    "predictions = text_classifier.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### 4. SAP - Adat előkészítés és tisztítás ####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ling_full = pd.read_sql(\"select content from reviews where length(content) < 5001\", connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thanks for providing these insights.  Really e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Super excited to see this podcast grow. So man...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm a liberal myself, but its pretty obvious a...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I find Tedx talks very inspirational but I oft...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I love this podcast, it is so good.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  id\n",
       "0  Thanks for providing these insights.  Really e...   1\n",
       "1  Super excited to see this podcast grow. So man...   2\n",
       "2  I'm a liberal myself, but its pretty obvious a...   3\n",
       "3  I find Tedx talks very inspirational but I oft...   4\n",
       "4                I love this podcast, it is so good.   5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ling_full[\"id\"] = ling_full.index + 1\n",
    "ling_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-b009237839b1>:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ling_full['content'] = ling_full['content'].str.replace('[^\\w\\s]','')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    Thanks for providing these insights  Really en...\n",
       "1    Super excited to see this podcast grow So many...\n",
       "2    Im a liberal myself but its pretty obvious and...\n",
       "3    I find Tedx talks very inspirational but I oft...\n",
       "4                    I love this podcast it is so good\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove points\n",
    "ling_full['content'] = ling_full['content'].str.replace('[^\\w\\s]','')\n",
    "ling_full['content'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove emojis\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags \n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "ling_full['content'] = ling_full['content'].apply(lambda x: remove_emoji(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thanks providing insights Really enjoy variety...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Super excited see podcast grow So many fun top...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Im liberal pretty obvious annoying theyre tryi...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I find Tedx talks inspirational I often dont t...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I love podcast good</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I listened Spanish Flu pod cast After 20 minut...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Too much BS trying convince racist sexist coun...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I would love hear topics discussed without pol...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ok I love podcast</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Great podcast editors turn volume talks The in...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>This episode touched impoverished mom It encou...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I love TedTalkx I love podcast days 3 episodes...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>I new podcasts listen allot I still finding on...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Love show STOP playing old episodes Im tired o...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I usually like TED talks every single one came...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>After seeing conservative reviews whining cons...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>I love Ted Talks sunk deeper deeper liberal pr...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Short varied The appropriate duration podcast ...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>I try listen TED TALK every day I offer Could ...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Mostly bad Is 5050 ratio empirical science rac...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              content  id\n",
       "0   Thanks providing insights Really enjoy variety...   1\n",
       "1   Super excited see podcast grow So many fun top...   2\n",
       "2   Im liberal pretty obvious annoying theyre tryi...   3\n",
       "3   I find Tedx talks inspirational I often dont t...   4\n",
       "4                                 I love podcast good   5\n",
       "5   I listened Spanish Flu pod cast After 20 minut...   6\n",
       "6   Too much BS trying convince racist sexist coun...   7\n",
       "7   I would love hear topics discussed without pol...   8\n",
       "8                                   Ok I love podcast   9\n",
       "9   Great podcast editors turn volume talks The in...  10\n",
       "10  This episode touched impoverished mom It encou...  11\n",
       "11  I love TedTalkx I love podcast days 3 episodes...  12\n",
       "12  I new podcasts listen allot I still finding on...  13\n",
       "13  Love show STOP playing old episodes Im tired o...  14\n",
       "14  I usually like TED talks every single one came...  15\n",
       "15  After seeing conservative reviews whining cons...  16\n",
       "16  I love Ted Talks sunk deeper deeper liberal pr...  17\n",
       "17  Short varied The appropriate duration podcast ...  18\n",
       "18  I try listen TED TALK every day I offer Could ...  19\n",
       "19  Mostly bad Is 5050 ratio empirical science rac...  20"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove stop words\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "ling_full['content'] = ling_full['content'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "\n",
    "ling_full.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ling_full.to_csv('C:/Users/Zen/Desktop/Egyetem/Szakdolgozat/Text-Analysis/ling_full.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
