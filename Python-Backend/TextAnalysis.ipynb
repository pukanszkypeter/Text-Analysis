{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB Connection\n",
    "import sqlite3\n",
    "\n",
    "# Casual\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# For Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# For Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# NLTK\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.classify import SklearnClassifier\n",
    "import re\n",
    "\n",
    "# Wordcloud\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "\n",
    "# Train - Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Testing\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Dump Models\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### SZÖVEGELEMZÉS (KATEGÓRIA PREDIKTÁLÁS, ÉRZELEM OSZTÁLYOZÁS) ####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adatbázis\n",
    "\n",
    "connection = sqlite3.connect(\"podcasts.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### 1. KATEGÓRIA PREDIKCIÓ - TELJES ####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adat betöltés\n",
    "\n",
    "full_cat_pred = pd.read_sql(\"select reviews.content, categories.category from reviews, categories where reviews.podcast_id = categories.podcast_id\", connection)\n",
    "full_cat_pred_content = full_cat_pred['content'].values.tolist()\n",
    "full_cat_pred_category = full_cat_pred['category'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer()),\n",
       "                ('multinomialnb', MultinomialNB())])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tanulás\n",
    "\n",
    "fullcatpred = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "fullcatpred.fit(full_cat_pred_content, full_cat_pred_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['business']\n"
     ]
    }
   ],
   "source": [
    "# Prediktálás\n",
    "\n",
    "def predict_category_full(s):\n",
    "    pred = fullcatpred.predict([s])\n",
    "    return pred\n",
    "\n",
    "print(predict_category_full('bank system, valuta, credit card'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mentés\n",
    "\n",
    "pickle.dump(fullcatpred, open('fullcatpred.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### 2. KATEGÓRIA PREDIKCIÓ - RÉSZLEGES ####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adat betöltés\n",
    "\n",
    "par_cat_pred = pd.read_sql(\"select reviews.content, categories.category from reviews, categories where reviews.podcast_id = categories.podcast_id\", connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Szelektálás\n",
    "\n",
    "categories = ['technology', 'arts-food','hinduism', 'spirituality']\n",
    "\n",
    "def decision_maker(subject, categories):\n",
    "    x = False\n",
    "    for cat in categories:\n",
    "        if subject == cat:\n",
    "            x = True  \n",
    "    return x\n",
    "\n",
    "par_cat_pred_content = []\n",
    "par_cat_pred_category = []\n",
    "\n",
    "for ind in par_cat_pred.index:\n",
    "    if (decision_maker(par_cat_pred['category'][ind], categories)):\n",
    "        par_cat_pred_content.append(par_cat_pred['content'][ind])\n",
    "        par_cat_pred_category.append(par_cat_pred['category'][ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer()),\n",
       "                ('multinomialnb', MultinomialNB())])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tanulás\n",
    "\n",
    "parcatpred = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "parcatpred.fit(par_cat_pred_content, par_cat_pred_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arts-food']\n"
     ]
    }
   ],
   "source": [
    "# Prediktálás\n",
    "\n",
    "def predict_category_par(s):\n",
    "    pred = parcatpred.predict([s])\n",
    "    return pred\n",
    "\n",
    "print(predict_category_par('hamburger, tasty, cheese, milk'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mentés\n",
    "\n",
    "# Web alkalmazás logika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### 3. ÉRZELEM OSZTÁLYOZÁS ####################\n",
    "# https://stackabuse.com/python-for-nlp-sentiment-analysis-with-scikit-learn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    996894\n",
       "0    151320\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adat betöltés\n",
    "\n",
    "sentiment_data = pd.read_sql(\"\"\"\n",
    "    select\n",
    "        content,\n",
    "        case when rating < 5 then 0\n",
    "            when rating > 4 then 1\n",
    "        end as sentiment\n",
    "    from reviews\n",
    "\"\"\", connection)\n",
    "\n",
    "sentiment_data.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adat csökkentés\n",
    "\n",
    "sentiment_data_positive = sentiment_data[sentiment_data['sentiment'] == 1].head(150000)\n",
    "sentiment_data_negative = sentiment_data[sentiment_data['sentiment'] == 0].head(150000)\n",
    "\n",
    "frames = [sentiment_data_positive, sentiment_data_negative]\n",
    "\n",
    "sentiment = pd.concat(frames, ignore_index=True)\n",
    "features = sentiment.content\n",
    "labels = sentiment.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tisztítás\n",
    "\n",
    "processed_features = []\n",
    "\n",
    "for sentence in range(0, len(features)):\n",
    "    # Remove all the special characters\n",
    "    processed_feature = re.sub(r'\\W', ' ', str(features[sentence]))\n",
    "\n",
    "    # remove all single characters\n",
    "    processed_feature= re.sub(r'\\s+[a-zA-Z]\\s+', ' ', processed_feature)\n",
    "\n",
    "    # Remove single characters from the start\n",
    "    processed_feature = re.sub(r'\\^[a-zA-Z]\\s+', ' ', processed_feature) \n",
    "\n",
    "    # Substituting multiple spaces with single space\n",
    "    processed_feature = re.sub(r'\\s+', ' ', processed_feature, flags=re.I)\n",
    "\n",
    "    # Removing prefixed 'b'\n",
    "    processed_feature = re.sub(r'^b\\s+', '', processed_feature)\n",
    "\n",
    "    # Converting to Lowercase\n",
    "    processed_feature = processed_feature.lower()\n",
    "\n",
    "    processed_features.append(processed_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF - IDF\n",
    "\n",
    "vectorizer = TfidfVectorizer (max_features=200, min_df=7, max_df=0.8, stop_words=stopwords.words('english'))\n",
    "processed_features = vectorizer.fit_transform(processed_features).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF - IDF Mentés\n",
    "\n",
    "pickle.dump(vectorizer, open('tfidf.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train - Test Split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(processed_features, labels, test_size=0.05, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=200, random_state=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tanulás\n",
    "\n",
    "text_classifier = RandomForestClassifier(n_estimators=200, random_state=0)\n",
    "text_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Mentés\n",
    "\n",
    "pickle.dump(text_classifier, open('textclassifier.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5822 1625]\n",
      " [1730 5823]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.78      0.78      7447\n",
      "           1       0.78      0.77      0.78      7553\n",
      "\n",
      "    accuracy                           0.78     15000\n",
      "   macro avg       0.78      0.78      0.78     15000\n",
      "weighted avg       0.78      0.78      0.78     15000\n",
      "\n",
      "0.7763333333333333\n"
     ]
    }
   ],
   "source": [
    "# Tesztelés\n",
    "\n",
    "predictions = text_classifier.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
